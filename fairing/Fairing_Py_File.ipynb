{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train tensorflow or keras model in .py files on GCP or Kubeflow from Notebooks\n",
    "\n",
    "This notebook introduces you to using Kubeflow Fairing to train the model, which is developed using tensorflow or keras and enclosed in python files, to Kubeflow on Google Kubernetes Engine (GKE), and Google Cloud AI Platform training. This notebook demonstrate how to:\n",
    " \n",
    "* Use Kubeflow Fairing to train an Tensorflow model remotely on Kubeflow cluster,\n",
    "* Use Kubeflow Fairing to train an Tensorflow model remotely on AI Platform training,\n",
    "\n",
    "**You need Python 3.6 to use Kubeflow Fairing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setups\n",
    "\n",
    "* Pre-conditions\n",
    "    - Deployed a kubeflow cluster through https://deploy.kubeflow.cloud/\n",
    "    - Have the following environment variable ready: \n",
    "        - PROJECT_ID # project host the kubeflow cluster or for running AI platform training\n",
    "        - DEPLOYMENT_NAME # kubeflow deployment name, the same the cluster name after delpoyed\n",
    "        - GCP_BUCKET # google cloud storage bucket\n",
    "\n",
    "* Create service account\n",
    "```bash\n",
    "export SA_NAME = [service account name]\n",
    "gcloud iam service-accounts create ${SA_NAME}\n",
    "gcloud projects add-iam-policy-binding ${PROJECT_ID} \\\n",
    "    --member serviceAccount:${SA_NAME}@${PROJECT_ID}.iam.gserviceaccount.com \\\n",
    "    --role 'roles/editor'\n",
    "gcloud iam service-accounts keys create ~/key.json \\\n",
    "    --iam-account ${SA_NAME}@${PROJECT_ID}.iam.gserviceaccount.com\n",
    "```\n",
    "\n",
    "* Authorize for Source Repository\n",
    "```bash\n",
    "gcloud auth configure-docker\n",
    "```\n",
    "\n",
    "* Update local kubeconfig (for submiting job to kubeflow cluster)\n",
    "```bash\n",
    "export CLUSTER_NAME=${DEPLOYMENT_NAME} # this is the deployment name or the kubenete cluster name\n",
    "export ZONE=us-central1-c\n",
    "gcloud container clusters get-credentials ${CLUSTER_NAME} --region ${ZONE}\n",
    "```\n",
    "\n",
    "* Set the environmental variable: GOOGLE_APPLICATION_CREDENTIALS\n",
    "```bash\n",
    "export GOOGLE_APPLICATION_CREDENTIALS = ....\n",
    "```\n",
    "```python\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS']=...\n",
    "```\n",
    "\n",
    "* Install the lastest version of fairing\n",
    "```python\n",
    "pip install git+https://github.com/kubeflow/fairing@master\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please not that the above configuration is required for notebook service running outside Kubeflow environment. And the examples demonstrated in the notebook is fully tested on notebook service outside Kubeflow cluster also.**\n",
    "\n",
    "**The environemt variables, e.g. service account, projects and etc, should have been pre-configured while setting up the cluster.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fairing\n",
    "from fairing.cloud import gcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trykube-248403\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fairing\n",
    "\n",
    "# Setting up google container repositories (GCR) for storing output containers\n",
    "# You can use any docker container registry istead of GCR\n",
    "# For local notebook, GCP_PROJECT should be set explicitly\n",
    "GCP_PROJECT = fairing.cloud.gcp.guess_project_name()\n",
    "GCP_Bucket ='gs://kubeflow-trykube/'\n",
    "print(GCP_PROJECT)\n",
    "# This is for local notebook instead of that in kubeflow cluster\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS']="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this demo, I use gsutil, therefore i compile a special image to install GoogleCloudSDK as based image\n",
    "# base_image = 'gcr.io/{}/fairing-predict-example:latest'.format(GCP_PROJECT)\n",
    "# !docker build --build-arg PY_VERSION=3.6.4 . -t {base_image}\n",
    "# !docker push {base_image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCKER_REGISTRY = 'gcr.io/{}/fairing-job-tf'.format(GCP_PROJECT)\n",
    "BASE_IMAGE = 'gcr.io/{}/fairing-predict-example:latest'.format(GCP_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'model.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the training job to AI platform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using preprocessor: <fairing.preprocessors.base.BasePreProcessor object at 0x11f4fe128>\n",
      "Using builder: <fairing.builders.docker.docker.DockerBuilder object at 0x11f4fee48>\n",
      "file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luoshixin/LocalSim/virtualPython36/lib/python3.6/site-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
      "    from google.appengine.api import memcache\n",
      "ModuleNotFoundError: No module named 'google.appengine'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luoshixin/LocalSim/virtualPython36/lib/python3.6/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
      "    from oauth2client.contrib.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luoshixin/LocalSim/virtualPython36/lib/python3.6/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
      "    from oauth2client.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luoshixin/LocalSim/virtualPython36/lib/python3.6/site-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
      "    from . import file_cache\n",
      "  File \"/Users/luoshixin/LocalSim/virtualPython36/lib/python3.6/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
      "    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')\n",
      "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
      "URL being requested: GET https://www.googleapis.com/discovery/v1/apis/ml/v1/rest\n",
      "Building image using docker\n",
      "Docker command: ['python', '/app/model.py']\n",
      "Creating docker context: /tmp/fairing_context_6ulb5qmv\n",
      "Context: /tmp/fairing_context_6ulb5qmv, Adding /Users/luoshixin/LocalSim/virtualPython36/lib/python3.6/site-packages/fairing/__init__.py at /app/fairing/__init__.py\n",
      "Context: /tmp/fairing_context_6ulb5qmv, Adding /Users/luoshixin/LocalSim/virtualPython36/lib/python3.6/site-packages/fairing/runtime_config.py at /app/fairing/runtime_config.py\n",
      "Context: /tmp/fairing_context_6ulb5qmv, Adding model.py at /app/model.py\n",
      "Context: /tmp/fairing_context_6ulb5qmv, Adding requirements.txt at /app/requirements.txt\n",
      "Context: /tmp/fairing_context_6ulb5qmv, Adding /tmp/fairing_dockerfile_ju8v9_bp at Dockerfile\n",
      "Building docker image gcr.io/gojek-kubeflow/fairing-job-tf/fairing-job:F0D4918E...\n",
      "Build output: Step 1/7 : FROM gcr.io/gojek-kubeflow/fairing-predict-example:latest\n",
      "Build output: \n",
      "Build output: ---> 07b0c0a773a2\n",
      "Build output: Step 2/7 : WORKDIR /app/\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> e38aad2dc182\n",
      "Build output: Step 3/7 : ENV FAIRING_RUNTIME 1\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> 597bd070338a\n",
      "Build output: Step 4/7 : COPY /app//requirements.txt /app/\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> 05e78d5eb908\n",
      "Build output: Step 5/7 : RUN if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> e31aa3ffcc59\n",
      "Build output: Step 6/7 : COPY /app/ /app/\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> 710caec21dce\n",
      "Build output: Step 7/7 : CMD python /app/model.py\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> d52847d8c0d9\n",
      "Push finished: {'ID': 'sha256:d52847d8c0d9ba6599a6f0f8c85a21fbe0d03ac17093ec6792ed92ab82dfe5fb'}\n",
      "Build output: Successfully built d52847d8c0d9\n",
      "Build output: Successfully tagged gcr.io/gojek-kubeflow/fairing-job-tf/fairing-job:F0D4918E\n",
      "Publishing image gcr.io/gojek-kubeflow/fairing-job-tf/fairing-job:F0D4918E...\n",
      "Push output: The push refers to repository [gcr.io/gojek-kubeflow/fairing-job-tf/fairing-job] None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: F0D4918E: digest: sha256:55679cf333fc88efc221d4ba7cede8d88658d210c7ec045bda3160199575a157 size: 3472 None\n",
      "Push finished: {'Tag': 'F0D4918E', 'Digest': 'sha256:55679cf333fc88efc221d4ba7cede8d88658d210c7ec045bda3160199575a157', 'Size': 3472}\n",
      "URL being requested: POST https://ml.googleapis.com/v1/projects/gojek-kubeflow/jobs?alt=json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training job with the following options: {'jobId': 'fairing_job_5310fcf1', 'trainingInput': {'masterConfig': {'imageUri': 'gcr.io/gojek-kubeflow/fairing-job-tf/fairing-job:F0D4918E'}, 'region': 'us-central1'}}\n",
      "Job submitted successfully.\n",
      "Access job logs at the following URL:\n",
      "https://console.cloud.google.com/mlengine/jobs/fairing_job_5310fcf1?project=gojek-kubeflow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<fairing.preprocessors.base.BasePreProcessor at 0x11f4fe128>,\n",
       " <fairing.builders.docker.docker.DockerBuilder at 0x11f4fee48>,\n",
       " <fairing.deployers.gcp.gcp.GCPJob at 0x11f4fefd0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairing.config.set_preprocessor('python', executable=file_name, input_files=[file_name, 'requirements.txt'])\n",
    "fairing.config.set_builder(name='cluster', registry=DOCKER_REGISTRY, base_image=BASE_IMAGE, push=True, \n",
    "                           pod_spec_mutators=[gcp.add_gcp_credentials_if_exists])\n",
    "fairing.config.set_deployer(name='gcp', pod_spec_mutators=[gcp.add_gcp_credentials_if_exists])\n",
    "fairing.config.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the training job to kubeflow cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for fairing-builder-v69fn to start...\n",
      "Waiting for fairing-builder-v69fn to start...\n",
      "Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image gcr.io/trykube-248403/fairing-predict-example:latest\n",
      "\u001b[36mINFO\u001b[0m[0002] Executing 0 build triggers\n",
      "\u001b[36mINFO\u001b[0m[0002] Unpacking rootfs as cmd RUN if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi requires it.\n",
      "\u001b[36mINFO\u001b[0m[0050] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0067] Skipping paths under /dev, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0067] Skipping paths under /etc/secrets, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0067] Skipping paths under /kaniko, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0067] Skipping paths under /proc, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0067] Skipping paths under /sys, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0067] Skipping paths under /var/run, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0087] WORKDIR /app/\n",
      "\u001b[36mINFO\u001b[0m[0087] cmd: workdir\n",
      "\u001b[36mINFO\u001b[0m[0087] Changed working directory to /app\n",
      "\u001b[36mINFO\u001b[0m[0087] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0107] Skipping paths under /dev, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0107] Skipping paths under /etc/secrets, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0107] Skipping paths under /kaniko, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0107] Skipping paths under /proc, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0107] Skipping paths under /sys, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0108] Skipping paths under /var/run, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0120] No files were changed, appending empty layer to config. No layer added to image.\n",
      "\u001b[36mINFO\u001b[0m[0120] ENV FAIRING_RUNTIME 1\n",
      "\u001b[36mINFO\u001b[0m[0120] Using files from context: [/kaniko/buildcontext/app/requirements.txt]\n",
      "\u001b[36mINFO\u001b[0m[0120] COPY /app//requirements.txt /app/\n",
      "\u001b[36mINFO\u001b[0m[0120] Taking snapshot of files...\n",
      "\u001b[36mINFO\u001b[0m[0120] RUN if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi\n",
      "\u001b[36mINFO\u001b[0m[0120] cmd: /bin/sh\n",
      "\u001b[36mINFO\u001b[0m[0120] args: [-c if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi]\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.25.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.13.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.90)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (0.0)\n",
      "Requirement already satisfied: seldon-core in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.3.1)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 1)) (2019.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/site-packages (from xgboost->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/site-packages (from sklearn->-r requirements.txt (line 5)) (0.21.3)\n",
      "Requirement already satisfied: flask in /usr/local/lib/python3.6/site-packages (from seldon-core->-r requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: Flask-OpenTracing==0.2.0 in /usr/local/lib/python3.6/site-packages (from seldon-core->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: opentracing<2,>=1.2.2 in /usr/local/lib/python3.6/site-packages (from seldon-core->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: flask-cors in /usr/local/lib/python3.6/site-packages (from seldon-core->-r requirements.txt (line 6)) (3.0.8)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.6/site-packages (from seldon-core->-r requirements.txt (line 6)) (1.11)\n",
      "Requirement already satisfied: grpcio-opentracing in /usr/local/lib/python3.6/site-packages (from seldon-core->-r requirements.txt (line 6)) (1.1.4)\n",
      "Requirement already satisfied: jaeger-client==3.13.0 in /usr/local/lib/python3.6/site-packages (from seldon-core->-r requirements.txt (line 6)) (3.13.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/site-packages (from seldon-core->-r requirements.txt (line 6)) (5.1.1)\n",
      "Requirement already satisfied: grpcio in /usr/local/lib/python3.6/site-packages (from seldon-core->-r requirements.txt (line 6)) (1.22.0)\n",
      "Requirement already satisfied: redis in /usr/local/lib/python3.6/site-packages (from seldon-core->-r requirements.txt (line 6)) (3.3.4)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/site-packages (from seldon-core->-r requirements.txt (line 6)) (3.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/site-packages (from seldon-core->-r requirements.txt (line 6)) (2.22.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 7)) (1.14.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 7)) (1.0.8)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 7)) (0.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 7)) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 7)) (0.32.2)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 7)) (1.14.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 7)) (1.12.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 7)) (0.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 7)) (0.1.7)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/site-packages (from flask->seldon-core->-r requirements.txt (line 6)) (0.15.5)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/site-packages (from flask->seldon-core->-r requirements.txt (line 6)) (2.10.1)\n",
      "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/site-packages (from flask->seldon-core->-r requirements.txt (line 6)) (7.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/site-packages (from flask->seldon-core->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: threadloop<2,>=1 in /usr/local/lib/python3.6/site-packages (from jaeger-client==3.13.0->seldon-core->-r requirements.txt (line 6)) (1.0.2)\n",
      "Requirement already satisfied: thrift in /usr/local/lib/python3.6/site-packages (from jaeger-client==3.13.0->seldon-core->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: tornado<5,>=4.3 in /usr/local/lib/python3.6/site-packages (from jaeger-client==3.13.0->seldon-core->-r requirements.txt (line 6)) (4.5.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/site-packages (from protobuf->seldon-core->-r requirements.txt (line 6)) (40.6.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests->seldon-core->-r requirements.txt (line 6)) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests->seldon-core->-r requirements.txt (line 6)) (1.25.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests->seldon-core->-r requirements.txt (line 6)) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests->seldon-core->-r requirements.txt (line 6)) (2.8)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow->-r requirements.txt (line 7)) (3.1.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow->-r requirements.txt (line 7)) (2.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/site-packages (from Jinja2>=2.10.1->flask->seldon-core->-r requirements.txt (line 6)) (1.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mINFO\u001b[0m[0122] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0122] Skipping paths under /dev, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0122] Skipping paths under /etc/secrets, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0122] Skipping paths under /kaniko, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0122] Skipping paths under /proc, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0122] Skipping paths under /sys, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0123] Skipping paths under /var/run, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0135] Using files from context: [/kaniko/buildcontext/app]\n",
      "\u001b[36mINFO\u001b[0m[0135] COPY /app/ /app/\n",
      "\u001b[36mINFO\u001b[0m[0135] Taking snapshot of files...\n",
      "2019/07/31 08:41:37 existing blob: sha256:c60eba308238780085602c72a69337c634aba5207d54d2369ddd92e4120f808f\n",
      "2019/07/31 08:41:37 existing blob: sha256:0c1db95989906f161007d8ef2a6ef6e0ec64bc15bf2c993fd002edbdfc7aa7df\n",
      "2019/07/31 08:41:37 existing blob: sha256:5d71636fb824265e30ff34bf20737c9cdc4f5af28b6bce86f08215c55b89bfab\n",
      "2019/07/31 08:41:37 existing blob: sha256:087a57faf9491b1b82a83e26bc8cc90c90c30e4a4d858b57ddd5b4c2c90095f6\n",
      "2019/07/31 08:41:37 existing blob: sha256:3ae1eaa188d6c2f435213bce9a22318adb11d071ec01198affb8a3886f6f2495\n",
      "2019/07/31 08:41:37 existing blob: sha256:041cd0421648e4d2475068b2a57abe52210afeddd6d9d30f18093d1db9b1a895\n",
      "2019/07/31 08:41:37 existing blob: sha256:a8c5303780550b746a4781e5e4cd893121d8019e971414a2a1273d54486b4eb9\n",
      "2019/07/31 08:41:37 existing blob: sha256:687ed2fb2a0d7da5503478759fd00c23970b65d02b317119b3fb9025038a2594\n",
      "2019/07/31 08:41:37 existing blob: sha256:620aea26e85367b08cdf1f6768491fb44df6a2a71f7d663f835b1692e849c3ee\n",
      "2019/07/31 08:41:37 existing blob: sha256:2eeb5ce9b9240a928b0a799f9f2601027e2c6b7525394ae5c371f124058489d7\n",
      "2019/07/31 08:41:37 existing blob: sha256:54f7e8ac135a5f502a6ee9537ef3d64b1cd2fa570dc0a40b4d3b6f7ac81e7486\n",
      "2019/07/31 08:41:37 existing blob: sha256:b251d940695c89cba7645ba18409d57bc50de2b1ae3500e7c7645b3ef8b81c3a\n",
      "2019/07/31 08:41:37 existing blob: sha256:d6341e30912f12f56e18564a3b582853f65376766f5f9d641a68a724ed6db88f\n",
      "2019/07/31 08:41:41 pushed blob sha256:4e5a41f1a74e41602c009d41f4b524602855328423a982353f05e1649a0dfb4c\n",
      "2019/07/31 08:41:42 pushed blob sha256:5e643fe52847ec96135452975cb02796a781d88472c544724ba5a04e865b4586\n",
      "2019/07/31 08:41:42 pushed blob sha256:16bcf35dbfb664f8245d176f1613e1f2019b25ceaa9eee0c0af951592f8b3522\n",
      "2019/07/31 08:41:42 pushed blob sha256:da9b748f43a094ecfd85b6bea7d319901cbf7a5efa753e013e80b3aefac12427\n",
      "2019/07/31 08:41:45 gcr.io/trykube-248403/fairing-job-tf/fairing-job:D9F4CCD3: digest: sha256:a8ba1fa174d6197e2e9c886fbe458ca7962de89e4d7724e3515ffd481bf5e260 size: 2883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training job fairing-job-bf972 launched.\n",
      "Waiting for fairing-job-bf972-mjlfb to start...\n",
      "Waiting for fairing-job-bf972-mjlfb to start...\n",
      "Waiting for fairing-job-bf972-mjlfb to start...\n",
      "Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0731 08:41:56.680246 139767480002304 deprecation_wrapper.py:119] From /app/model.py:240: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "W0731 08:41:56.680960 139767480002304 deprecation_wrapper.py:119] From /app/model.py:160: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0731 08:41:56.681135 139767480002304 deprecation_wrapper.py:119] From /app/model.py:160: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W0731 08:41:56.682858 139767480002304 deprecation_wrapper.py:119] From /app/model.py:165: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "I0731 08:41:56.682994 139767480002304 model.py:165] TF_CONFIG {}\n",
      "I0731 08:41:56.683808 139767480002304 model.py:171] cluster=None job_name=None task_index=None\n",
      "I0731 08:41:56.683904 139767480002304 model.py:176] Will export model\n",
      "W0731 08:41:57.552948 139767480002304 lazy_loader.py:50]\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0731 08:41:57.553343 139767480002304 deprecation.py:323] From /app/model.py:181: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0731 08:41:57.553542 139767480002304 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0731 08:41:57.553694 139767480002304 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0731 08:41:57.554136 139767480002304 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "W0731 08:41:58.152947 139767480002304 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0731 08:41:58.631393 139767480002304 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0731 08:41:59.289106 139767480002304 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0731 08:41:59.587442 139767480002304 deprecation_wrapper.py:119] From /app/model.py:182: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "W0731 08:41:59.587753 139767480002304 deprecation_wrapper.py:119] From /app/model.py:182: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\n",
      "I0731 08:41:59.588837 139767480002304 estimator.py:209] Using config: {'_model_dir': '/tmp/tensorflow/logs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1df8449b00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I0731 08:41:59.589509 139767480002304 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "I0731 08:41:59.589782 139767480002304 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "I0731 08:41:59.590088 139767480002304 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "W0731 08:41:59.596638 139767480002304 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0731 08:41:59.613667 139767480002304 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0731 08:41:59.615364 139767480002304 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0731 08:41:59.624819 139767480002304 estimator.py:1145] Calling model_fn.\n",
      "W0731 08:41:59.626539 139767480002304 deprecation_wrapper.py:119] From /app/model.py:83: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0731 08:41:59.626967 139767480002304 deprecation.py:323] From /app/model.py:89: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0731 08:41:59.629800 139767480002304 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0731 08:41:59.993082 139767480002304 deprecation.py:323] From /app/model.py:91: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "W0731 08:42:00.184135 139767480002304 deprecation.py:323] From /app/model.py:107: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0731 08:42:00.531209 139767480002304 deprecation.py:323] From /app/model.py:111: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0731 08:42:00.632676 139767480002304 deprecation_wrapper.py:119] From /app/model.py:131: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "W0731 08:42:00.644682 139767480002304 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0731 08:42:00.655506 139767480002304 deprecation_wrapper.py:119] From /app/model.py:135: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "W0731 08:42:00.655780 139767480002304 deprecation_wrapper.py:119] From /app/model.py:137: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\n",
      "I0731 08:42:00.752370 139767480002304 estimator.py:1147] Done calling model_fn.\n",
      "I0731 08:42:00.754144 139767480002304 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0731 08:42:00.881066 139767480002304 monitored_session.py:240] Graph was finalized.\n",
      "2019-07-31 08:42:00.881511: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-07-31 08:42:00.891862: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2019-07-31 08:42:00.892573: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55db861a8690 executing computations on platform Host. Devices:\n",
      "2019-07-31 08:42:00.892628: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-07-31 08:42:00.920711: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "I0731 08:42:00.951376 139767480002304 session_manager.py:500] Running local_init_op.\n",
      "I0731 08:42:00.957219 139767480002304 session_manager.py:502] Done running local_init_op.\n",
      "W0731 08:42:00.973674 139767480002304 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0731 08:42:01.166361 139767480002304 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tensorflow/logs/model.ckpt.\n",
      "I0731 08:42:01.397788 139767480002304 basic_session_run_hooks.py:262] loss = 2.3071723, step = 1\n",
      "I0731 08:42:08.992114 139767480002304 basic_session_run_hooks.py:692] global_step/sec: 13.1669\n",
      "I0731 08:42:08.993203 139767480002304 basic_session_run_hooks.py:260] loss = 2.0576665, step = 101 (7.595 sec)\n",
      "I0731 08:42:16.672158 139767480002304 basic_session_run_hooks.py:606] Saving checkpoints for 200 into /tmp/tensorflow/logs/model.ckpt.\n",
      "I0731 08:42:16.740451 139767480002304 estimator.py:1145] Calling model_fn.\n",
      "W0731 08:42:16.853159 139767480002304 deprecation_wrapper.py:119] From /app/model.py:142: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
      "\n",
      "I0731 08:42:16.873840 139767480002304 estimator.py:1147] Done calling model_fn.\n",
      "I0731 08:42:16.896817 139767480002304 evaluation.py:255] Starting evaluation at 2019-07-31T08:42:16Z\n",
      "I0731 08:42:16.991287 139767480002304 monitored_session.py:240] Graph was finalized.\n",
      "W0731 08:42:16.991875 139767480002304 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0731 08:42:16.993071 139767480002304 saver.py:1280] Restoring parameters from /tmp/tensorflow/logs/model.ckpt-200\n",
      "I0731 08:42:17.037907 139767480002304 session_manager.py:500] Running local_init_op.\n",
      "I0731 08:42:17.048670 139767480002304 session_manager.py:502] Done running local_init_op.\n",
      "I0731 08:42:17.127649 139767480002304 evaluation.py:167] Evaluation [1/1]\n",
      "I0731 08:42:17.172641 139767480002304 evaluation.py:275] Finished evaluation at 2019-07-31-08:42:17\n",
      "I0731 08:42:17.172914 139767480002304 estimator.py:2039] Saving dict for global step 200: accuracy = 0.7734375, global_step = 200, loss = 0.82372606\n",
      "I0731 08:42:17.211750 139767480002304 estimator.py:2099] Saving 'checkpoint_path' summary for global step 200: /tmp/tensorflow/logs/model.ckpt-200\n",
      "I0731 08:42:17.212632 139767480002304 exporter.py:410] Performing the final export in the end of training.\n",
      "W0731 08:42:17.219283 139767480002304 deprecation_wrapper.py:119] From /app/model.py:150: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "I0731 08:42:17.220488 139767480002304 estimator.py:1145] Calling model_fn.\n",
      "I0731 08:42:17.312561 139767480002304 estimator.py:1147] Done calling model_fn.\n",
      "W0731 08:42:17.312894 139767480002304 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "I0731 08:42:17.313482 139767480002304 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
      "I0731 08:42:17.313674 139767480002304 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
      "I0731 08:42:17.313798 139767480002304 export_utils.py:170] Signatures INCLUDED in export for Predict: ['classes', 'serving_default']\n",
      "I0731 08:42:17.313893 139767480002304 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
      "I0731 08:42:17.313977 139767480002304 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
      "I0731 08:42:17.340070 139767480002304 saver.py:1280] Restoring parameters from /tmp/tensorflow/logs/model.ckpt-200\n",
      "I0731 08:42:17.363951 139767480002304 builder_impl.py:661] Assets added to graph.\n",
      "I0731 08:42:17.364198 139767480002304 builder_impl.py:456] No assets to write.\n",
      "I0731 08:42:17.410151 139767480002304 builder_impl.py:421] SavedModel written to: /tmp/tensorflow/model/temp-b'1564562537'/saved_model.pb\n",
      "I0731 08:42:17.449811 139767480002304 estimator.py:368] Loss for final step: 1.0184075.\n",
      "W0731 08:42:17.450744 139767480002304 deprecation.py:323] From /app/model.py:236: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function has been renamed, use `export_saved_model` instead.\n",
      "W0731 08:42:18.455415 139767480002304 export_utils.py:225] Directory b'/tmp/tensorflow/model/1564562537' already exists; retrying (attempt 1/10)\n",
      "I0731 08:42:18.462433 139767480002304 estimator.py:1145] Calling model_fn.\n",
      "I0731 08:42:18.555665 139767480002304 estimator.py:1147] Done calling model_fn.\n",
      "I0731 08:42:18.556348 139767480002304 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
      "I0731 08:42:18.556515 139767480002304 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
      "I0731 08:42:18.556612 139767480002304 export_utils.py:170] Signatures INCLUDED in export for Predict: ['classes', 'serving_default']\n",
      "I0731 08:42:18.556700 139767480002304 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
      "I0731 08:42:18.556784 139767480002304 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0731 08:42:18.694576 139767480002304 saver.py:1280] Restoring parameters from /tmp/tensorflow/logs/model.ckpt-200\n",
      "I0731 08:42:18.718579 139767480002304 builder_impl.py:661] Assets added to graph.\n",
      "I0731 08:42:18.718801 139767480002304 builder_impl.py:456] No assets to write.\n",
      "I0731 08:42:18.762445 139767480002304 builder_impl.py:421] SavedModel written to: /tmp/tensorflow/model/temp-b'1564562538'/saved_model.pb\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/tensorflow/input_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/tensorflow/input_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/tensorflow/input_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/tensorflow/input_data/t10k-labels-idx1-ubyte.gz\n",
      "Train and evaluate\n",
      "Training done\n",
      "Export saved model\n",
      "Done exporting the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning up job fairing-job-bf972...\n"
     ]
    }
   ],
   "source": [
    "fairing.config.set_preprocessor('python', executable=file_name, input_files=[file_name, 'requirements.txt'])\n",
    "fairing.config.set_builder(name='cluster', registry=DOCKER_REGISTRY, base_image=BASE_IMAGE, push=True\n",
    "                           ,pod_spec_mutators=[gcp.add_gcp_credentials_if_exists])\n",
    "fairing.config.set_deployer(name='job', pod_spec_mutators=[gcp.add_gcp_credentials_if_exists])\n",
    "fairing.config.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark and XGboost Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import components\n",
    "from kfp import dsl\n",
    "from kfp import gcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load reusable components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0b07e456b1f319d8b7a7301274f55c00fda9f537/components/local/confusion_matrix/component.yaml')\n",
    "roc_op =              components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0b07e456b1f319d8b7a7301274f55c00fda9f537/components/local/roc/component.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cluster create and delete operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataproc_create_cluster_op(\n",
    "    project,\n",
    "    region,\n",
    "    staging,\n",
    "    cluster_name='xgb-{{workflow.name}}'\n",
    "):\n",
    "    return dsl.ContainerOp(\n",
    "        name='Dataproc - Create cluster',\n",
    "        image='gcr.io/ml-pipeline/ml-pipeline-dataproc-create-cluster:fe639f41661d8e17fcda64ff8242127620b80ba0',\n",
    "        arguments=[\n",
    "            '--project', project,\n",
    "            '--region', region,\n",
    "            '--name', cluster_name,\n",
    "            '--staging', staging,\n",
    "        ],\n",
    "        file_outputs={\n",
    "            'output': '/output.txt',\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def dataproc_delete_cluster_op(\n",
    "    project,\n",
    "    region,\n",
    "    cluster_name='xgb-{{workflow.name}}'\n",
    "):\n",
    "    return dsl.ContainerOp(\n",
    "        name='Dataproc - Delete cluster',\n",
    "        image='gcr.io/ml-pipeline/ml-pipeline-dataproc-delete-cluster:fe639f41661d8e17fcda64ff8242127620b80ba0',\n",
    "        arguments=[\n",
    "            '--project', project,\n",
    "            '--region', region,\n",
    "            '--name', cluster_name,\n",
    "        ],\n",
    "        is_exit_handler=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data analyze and transform operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataproc_analyze_op(\n",
    "    project,\n",
    "    region,\n",
    "    cluster_name,\n",
    "    schema,\n",
    "    train_data,\n",
    "    output\n",
    "):\n",
    "    return dsl.ContainerOp(\n",
    "        name='Dataproc - Analyze',\n",
    "        image='gcr.io/ml-pipeline/ml-pipeline-dataproc-analyze:fe639f41661d8e17fcda64ff8242127620b80ba0',\n",
    "        arguments=[\n",
    "            '--project', project,\n",
    "            '--region', region,\n",
    "            '--cluster', cluster_name,\n",
    "            '--schema', schema,\n",
    "            '--train', train_data,\n",
    "            '--output', output,\n",
    "        ],\n",
    "        file_outputs={\n",
    "            'output': '/output.txt',\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def dataproc_transform_op(\n",
    "    project,\n",
    "    region,\n",
    "    cluster_name,\n",
    "    train_data,\n",
    "    eval_data,\n",
    "    target,\n",
    "    analysis,\n",
    "    output\n",
    "):\n",
    "    return dsl.ContainerOp(\n",
    "        name='Dataproc - Transform',\n",
    "        image='gcr.io/ml-pipeline/ml-pipeline-dataproc-transform:fe639f41661d8e17fcda64ff8242127620b80ba0',\n",
    "        arguments=[\n",
    "            '--project', project,\n",
    "            '--region', region,\n",
    "            '--cluster', cluster_name,\n",
    "            '--train', train_data,\n",
    "            '--eval', eval_data,\n",
    "            '--analysis', analysis,\n",
    "            '--target', target,\n",
    "            '--output', output,\n",
    "        ],\n",
    "        file_outputs={\n",
    "            'train': '/output_train.txt',\n",
    "            'eval': '/output_eval.txt',\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training and prediction operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataproc_train_op(\n",
    "    project,\n",
    "    region,\n",
    "    cluster_name,\n",
    "    train_data,\n",
    "    eval_data,\n",
    "    target,\n",
    "    analysis,\n",
    "    workers,\n",
    "    rounds,\n",
    "    output,\n",
    "    is_classification=True\n",
    "):\n",
    "    if is_classification:\n",
    "        config='gs://ml-pipeline-playground/trainconfcla.json'\n",
    "    else:\n",
    "        config='gs://ml-pipeline-playground/trainconfreg.json'\n",
    "\n",
    "    return dsl.ContainerOp(\n",
    "        name='Dataproc - Train XGBoost model',\n",
    "        image='gcr.io/ml-pipeline/ml-pipeline-dataproc-train:fe639f41661d8e17fcda64ff8242127620b80ba0',\n",
    "        arguments=[\n",
    "            '--project', project,\n",
    "            '--region', region,\n",
    "            '--cluster', cluster_name,\n",
    "            '--train', train_data,\n",
    "            '--eval', eval_data,\n",
    "            '--analysis', analysis,\n",
    "            '--target', target,\n",
    "            '--package', 'gs://ml-pipeline-playground/xgboost4j-example-0.8-SNAPSHOT-jar-with-dependencies.jar',\n",
    "            '--workers', workers,\n",
    "            '--rounds', rounds,\n",
    "            '--conf', config,\n",
    "            '--output', output,\n",
    "        ],\n",
    "        file_outputs={\n",
    "            'output': '/output.txt',\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def dataproc_predict_op(\n",
    "    project,\n",
    "    region,\n",
    "    cluster_name,\n",
    "    data,\n",
    "    model,\n",
    "    target,\n",
    "    analysis,\n",
    "    output\n",
    "):\n",
    "    return dsl.ContainerOp(\n",
    "        name='Dataproc - Predict with XGBoost model',\n",
    "        image='gcr.io/ml-pipeline/ml-pipeline-dataproc-predict:fe639f41661d8e17fcda64ff8242127620b80ba0',\n",
    "        arguments=[\n",
    "            '--project', project,\n",
    "            '--region', region,\n",
    "            '--cluster', cluster_name,\n",
    "            '--predict', data,\n",
    "            '--analysis', analysis,\n",
    "            '--target', target,\n",
    "            '--package', 'gs://ml-pipeline-playground/xgboost4j-example-0.8-SNAPSHOT-jar-with-dependencies.jar',\n",
    "            '--model', model,\n",
    "            '--output', output,\n",
    "        ],\n",
    "        file_outputs={\n",
    "            'output': '/output.txt',\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='XGBoost Trainer',\n",
    "    description='A trainer that does end-to-end distributed training for XGBoost models.'\n",
    ")\n",
    "def xgb_train_pipeline(\n",
    "    output,\n",
    "    project,\n",
    "    region='us-central1',\n",
    "    train_data='gs://ml-pipeline-playground/sfpd/train.csv',\n",
    "    eval_data='gs://ml-pipeline-playground/sfpd/eval.csv',\n",
    "    schema='gs://ml-pipeline-playground/sfpd/schema.json',\n",
    "    target='resolution',\n",
    "    rounds=200,\n",
    "    workers=2,\n",
    "    true_label='ACTION',\n",
    "):\n",
    "    output_template = str(output) + '/{{workflow.uid}}/{{pod.name}}/data'\n",
    "\n",
    "    delete_cluster_op = dataproc_delete_cluster_op(\n",
    "        project,\n",
    "        region\n",
    "    ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "\n",
    "    with dsl.ExitHandler(exit_op=delete_cluster_op):\n",
    "        create_cluster_op = dataproc_create_cluster_op(\n",
    "            project,\n",
    "            region,\n",
    "            output\n",
    "        ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "\n",
    "        analyze_op = dataproc_analyze_op(\n",
    "            project,\n",
    "            region,\n",
    "            create_cluster_op.output,\n",
    "            schema,\n",
    "            train_data,\n",
    "            output_template\n",
    "        ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "\n",
    "        transform_op = dataproc_transform_op(\n",
    "            project,\n",
    "            region,\n",
    "            create_cluster_op.output,\n",
    "            train_data,\n",
    "            eval_data,\n",
    "            target,\n",
    "            analyze_op.output,\n",
    "            output_template\n",
    "        ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "\n",
    "        train_op = dataproc_train_op(\n",
    "            project,\n",
    "            region,\n",
    "            create_cluster_op.output,\n",
    "            transform_op.outputs['train'],\n",
    "            transform_op.outputs['eval'],\n",
    "            target,\n",
    "            analyze_op.output,\n",
    "            workers,\n",
    "            rounds,\n",
    "            output_template\n",
    "        ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "\n",
    "        predict_op = dataproc_predict_op(\n",
    "            project,\n",
    "            region,\n",
    "            create_cluster_op.output,\n",
    "            transform_op.outputs['eval'],\n",
    "            train_op.output,\n",
    "            target,\n",
    "            analyze_op.output,\n",
    "            output_template\n",
    "        ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "\n",
    "        confusion_matrix_task = confusion_matrix_op(\n",
    "            predict_op.output,\n",
    "            output_template\n",
    "        ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "\n",
    "        roc_task = roc_op(\n",
    "            predictions_dir=predict_op.output,\n",
    "            true_class=true_label,\n",
    "            true_score_column=true_label,\n",
    "            output_dir=output_template\n",
    "        ).apply(gcp.use_gcp_secret('user-gcp-sa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_func = xgb_train_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.pipeline.zip'\n",
    "kfp.compiler.Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/d2057d56-2b4c-435b-aba2-667dd8f044a5\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/9ab1e6ed-b4cf-11e9-8eb7-42010af00066\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Specify pipeline argument values\n",
    "arguments = {'output': 'gs://kubeflow-trykube/kubeflow-pipeline/spark',\n",
    "             'project': 'trykube-248403'}\n",
    "\n",
    "#Get or create an experiment and submit a pipeline run\n",
    "import kfp\n",
    "client = kfp.Client()\n",
    "experiment = client.create_experiment('Spark-and-XGBoost')\n",
    "\n",
    "#Submit a pipeline run\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

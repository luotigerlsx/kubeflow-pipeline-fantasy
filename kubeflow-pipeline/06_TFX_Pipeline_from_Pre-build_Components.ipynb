{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFX Pipeline from Pre-build Components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline demonstrates the TFX capabilities at scale. The pipeline uses a public BigQuery dataset and uses GCP services to preprocess data (Dataflow) and train the model (Cloud ML Engine). The model is then deployed to kubeflow for prediction service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import components\n",
    "from kfp import dsl\n",
    "from kfp import gcp\n",
    "import kfp.compiler as compiler\n",
    "\n",
    "import kubernetes as k8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameter"
    ]
   },
   "outputs": [],
   "source": [
    "# Required Parameters\n",
    "PROJECT_ID='<ADD GCP PROJECT HERE>'\n",
    "GCS_BUCKET='gs://<ADD STORAGE LOCATION HERE>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameter"
    ]
   },
   "outputs": [],
   "source": [
    "# Optional Parameters, but required for running outside kubeflow cluster\n",
    "HOST = '<ADD HOST NAME TO TALK TO KUBEFLOW PIPELINE HERE>'\n",
    "CLIENT_ID = '<ADD OAuth CLIENT ID USED BY IAP HERE>'\n",
    "OTHER_CLIENT_ID = '<ADD OAuth CLIENT ID USED TO OBTAIN AUTH CODES HERE>'\n",
    "OTHER_CLIENT_SECRET = '<ADD OAuth CLIENT SECRET USED TO OBTAIN AUTH CODES HERE>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create client\n",
    "\n",
    "**If submit outside the kubeflow cluster, need the following**\n",
    "- `host`: the host name to use to talk to Kubeflow Pipelines, i.e., \"https://`<your-deployment>`.endpoints.`<your-project>`.cloud.goog/pipeline\"\n",
    "- `client_id`: The client ID used by Identity-Aware Proxy\n",
    "- `other_client_id`: The client ID used to obtain the auth codes and refresh tokens.\n",
    "- `other_client_secret`: The client secret used to obtain the auth codes and refresh tokens.\n",
    "- For getting `other_client_id` and `other_client_secret`, you'll need to create OAuth client ID credentials of type `Other` according to the tutorial [here](\n",
    "https://cloud.google.com/iap/docs/authentication-howto#authenticating_from_a_desktop_app)\n",
    "```python\n",
    "client = kfp.Client(host, client_id, other_client_id, other_client_secret)\n",
    "```\n",
    "\n",
    "**If you run and submit within the kubeflow cluster**, the following is enough\n",
    "```python\n",
    "client = kfp.Client()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get or create an experiment and submit a pipeline run\n",
    "in_cluster = True\n",
    "try:\n",
    "  k8s.config.load_incluster_config()\n",
    "except:\n",
    "  in_cluster = False\n",
    "  pass\n",
    "\n",
    "if in_cluster:\n",
    "    client = kfp.Client()\n",
    "else:\n",
    "    client = kfp.Client(host=HOST, \n",
    "                        client_id=CLIENT_ID,\n",
    "                        other_client_id=OTHER_CLIENT_ID, \n",
    "                        other_client_secret=OTHER_CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-build components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataflow_tf_data_validation_op  = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0b07e456b1f319d8b7a7301274f55c00fda9f537/components/dataflow/tfdv/component.yaml')\n",
    "dataflow_tf_transform_op        = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0b07e456b1f319d8b7a7301274f55c00fda9f537/components/dataflow/tft/component.yaml')\n",
    "tf_train_op                     = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0b07e456b1f319d8b7a7301274f55c00fda9f537/components/kubeflow/dnntrainer/component.yaml')\n",
    "dataflow_tf_model_analyze_op    = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0b07e456b1f319d8b7a7301274f55c00fda9f537/components/dataflow/tfma/component.yaml')\n",
    "dataflow_tf_predict_op          = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0b07e456b1f319d8b7a7301274f55c00fda9f537/components/dataflow/predict/component.yaml')\n",
    "\n",
    "confusion_matrix_op             = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0b07e456b1f319d8b7a7301274f55c00fda9f537/components/local/confusion_matrix/component.yaml')\n",
    "roc_op                          = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0b07e456b1f319d8b7a7301274f55c00fda9f537/components/local/roc/component.yaml')\n",
    "\n",
    "kubeflow_deploy_op              = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0b07e456b1f319d8b7a7301274f55c00fda9f537/components/kubeflow/deployer/component.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and compile pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "  name='TFX Taxi Cab Classification Pipeline Example',\n",
    "  description='Example pipeline that does classification with model analysis based on a public BigQuery dataset.'\n",
    ")\n",
    "def taxi_cab_classification(\n",
    "    output,\n",
    "    project,\n",
    "    column_names='gs://ml-pipeline-playground/tfx/taxi-cab-classification/column-names.json',\n",
    "    key_columns='trip_start_timestamp',\n",
    "    train='gs://ml-pipeline-playground/tfx/taxi-cab-classification/train.csv',\n",
    "    evaluation='gs://ml-pipeline-playground/tfx/taxi-cab-classification/eval.csv',\n",
    "    mode='local',\n",
    "    preprocess_module='gs://ml-pipeline-playground/tfx/taxi-cab-classification/preprocessing.py',\n",
    "    learning_rate=0.1,\n",
    "    hidden_layer_size='1500',\n",
    "    steps=3000,\n",
    "    analyze_slice_column='trip_start_hour'\n",
    "):\n",
    "    output_template = str(output) + '/{{workflow.uid}}/{{pod.name}}/data'\n",
    "    target_lambda = \"\"\"lambda x: (x['target'] > x['fare'] * 0.2)\"\"\"\n",
    "    target_class_lambda = \"\"\"lambda x: 1 if (x['target'] > x['fare'] * 0.2) else 0\"\"\"\n",
    "\n",
    "    tf_server_name = 'taxi-cab-classification-model-{{workflow.uid}}'\n",
    "\n",
    "    validation = dataflow_tf_data_validation_op(\n",
    "        inference_data=train,\n",
    "        validation_data=evaluation,\n",
    "        column_names=column_names,\n",
    "        key_columns=key_columns,\n",
    "        gcp_project=project,\n",
    "        run_mode=mode,\n",
    "        validation_output=output_template,\n",
    "    )\n",
    "\n",
    "    preprocess = dataflow_tf_transform_op(\n",
    "        training_data_file_pattern=train,\n",
    "        evaluation_data_file_pattern=evaluation,\n",
    "        schema=validation.outputs['schema'],\n",
    "        gcp_project=project,\n",
    "        run_mode=mode,\n",
    "        preprocessing_module=preprocess_module,\n",
    "        transformed_data_dir=output_template\n",
    "    )\n",
    "\n",
    "    training = tf_train_op(\n",
    "        transformed_data_dir=preprocess.output,\n",
    "        schema=validation.outputs['schema'],\n",
    "        learning_rate=learning_rate,\n",
    "        hidden_layer_size=hidden_layer_size,\n",
    "        steps=steps,\n",
    "        optimizer='Adagrad',\n",
    "        target='tips',\n",
    "        preprocessing_module=preprocess_module,\n",
    "        training_output_dir=output_template\n",
    "    )\n",
    "\n",
    "    analysis = dataflow_tf_model_analyze_op(\n",
    "        model=training.output,\n",
    "        evaluation_data=evaluation,\n",
    "        schema=validation.outputs['schema'],\n",
    "        gcp_project=project,\n",
    "        run_mode=mode,\n",
    "        slice_columns=analyze_slice_column,\n",
    "        analysis_results_dir=output_template\n",
    "    )\n",
    "\n",
    "    prediction = dataflow_tf_predict_op(\n",
    "        data_file_pattern=evaluation,\n",
    "        schema=validation.outputs['schema'],\n",
    "        target_column='tips',\n",
    "        model=training.output,\n",
    "        batch_size=32,\n",
    "        run_mode=mode,\n",
    "        gcp_project=project,\n",
    "        predictions_dir=output_template\n",
    "    )\n",
    "\n",
    "    cm = confusion_matrix_op(\n",
    "        predictions=prediction.output,\n",
    "        target_lambda=target_lambda,\n",
    "        output_dir=output_template\n",
    "    )\n",
    "\n",
    "\n",
    "    deploy = kubeflow_deploy_op(\n",
    "        model_dir=str(training.output) + '/export/export',\n",
    "        server_name=tf_server_name,\n",
    "        cluster_name='kubeflow', \n",
    "        namespace='kubeflow',\n",
    "        pvc_name='', \n",
    "        service_type='ClusterIP'\n",
    "    )\n",
    "\n",
    "\n",
    "    steps = [validation, preprocess, training, analysis, prediction, cm, deploy]\n",
    "    for step in steps:\n",
    "        step.apply(gcp.use_gcp_secret('user-gcp-sa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoshixin/LocalSim/virtualPython35/lib/python3.5/site-packages/kfp/components/_data_passing.py:133: UserWarning: Missing type name was inferred as \"Float\" based on the value \"0.1\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/Users/luoshixin/LocalSim/virtualPython35/lib/python3.5/site-packages/kfp/components/_data_passing.py:133: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"3000\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://kubeflow1.endpoints.kubeflow-pipeline-fantasy.cloud.goog/pipeline/#/experiments/details/c3ab3ae6-ba0c-40fd-9957-94d41174565a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://kubeflow1.endpoints.kubeflow-pipeline-fantasy.cloud.goog/pipeline/#/runs/details/34cb661f-652d-47f4-b0ee-3876ee0a97ea\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_func = taxi_cab_classification\n",
    "pipeline_filename = pipeline_func.__name__ + '.pipeline.zip'\n",
    "\n",
    "compiler.Compiler().compile(pipeline_func, pipeline_filename)\n",
    "#Submit a pipeline run\n",
    "arguments = {\"project\":PROJECT_ID,\n",
    "             \"output\": GCS_BUCKET}\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "experiment = client.create_experiment('TFX-From-Components')\n",
    "\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)\n",
    "\n",
    "## Submit pipeline directly from pipeline function\n",
    "# client.create_run_from_pipeline_func(pipeline_func, experiment_name={}, run_name={} arguments={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualPython35",
   "language": "python",
   "name": "virtualpython35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
